{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b444e1f-5780-455f-bcb3-a6d861c10f3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Welcome to My Loan Default Project \n",
    "Dataset from Kaggle :https://www.kaggle.com/datasets/mishra5001/credit-card\n",
    "\n",
    "- Exploratory analysis to understand the data set, clean the data set, and identify key column for the analysis\n",
    "- Perform univariate, bivariate, and multivariate analysis for target categorical and numerical variables\n",
    "- Identifying the variables which can help in predicting high risk customers \n",
    "\n",
    "Assumtioons:เราไม่ทราบว่าลูกค้าพลาดการชำระเงินกี่ครั้ง ลูกค้าทุกคนที่พลาดการชำระเงินอย่างน้อยหนึ่งครั้งจะได้รับการรับมือเหมือนกันเหมือนกัน\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e7f33b-6d49-4832-8255-53c2c5f64530",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#read file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5f58065-28d2-4d39-bb5c-d374c11a6e73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# รานชื่อสมาชิก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b465a506-01df-4d9f-bd38-85f251c46d53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " - ปิยวัช ขันทนิเทศน์ 6504053620109\n",
    " - สุชาครีย์ ศีลาเจริญ 6504053620125\n",
    " - จิรภาส สามารถรัมย์ 6504053630023\n",
    " - สุธิภัทร จำเริญดี 6504053630171\n",
    " - นายกำภูกฤช ศรีวิเศษ 6504053630015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36d73927-bb97-4d8d-85c4-50268c74d65c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/s6504053620109@email.kmutnb.ac.th/application_data-4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11fa8d33-a2e6-4af6-90d2-d41ed35a9b2f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#import libary we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fff1b175-98cc-41ec-b760-12c3d10d1aea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import  warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col, count, when, isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fefeae40-da7f-4a95-9a4b-8b7d2a63ac30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''pip install xgboost pyspark'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b921dc2-e75a-4b2f-8cb5-a4678e9eee5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fbc8d48-2998-445a-84e6-7aa35bfe4199",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81c6611-da96-44ee-9dc3-995f7da532c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Reading the Input Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "693f25ef-9f34-4fe7-a6f3-3ff2cb9a89fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'\"app_df.display()\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "581b77b8-14fe-4709-8e16-c44592cf9b8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf21176-55fc-40d7-bf4f-32680809d353",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Datatype issue we need to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6125380a-4833-4dce-bcd2-cd0a117ac956",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# กำหนดคอลัมน์ที่ควรเป็น float และ int\n",
    "int_columns = ['SK_ID_CURR', 'TARGET', 'CNT_CHILDREN', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH',\n",
    "               'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "               'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START',\n",
    "               'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION',\n",
    "               'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2',\n",
    "               'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n",
    "               'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "               'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n",
    "               'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']\n",
    "\n",
    "float_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE',\n",
    "                 'OWN_CAR_AGE', 'CNT_FAM_MEMBERS', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG',\n",
    "                 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG',\n",
    "                 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG',\n",
    "                 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE',\n",
    "                 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE',\n",
    "                 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE',\n",
    "                 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI',\n",
    "                 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI',\n",
    "                 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI',\n",
    "                 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "                 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE',\n",
    "                 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
    "\n",
    "# แปลงคอลัมน์ที่ควรเป็น float\n",
    "for column in float_columns:\n",
    "    app_df = app_df.withColumn(column, col(column).cast(\"float\"))\n",
    "\n",
    "# แปลงคอลัมน์ที่ควรเป็น int\n",
    "for column in int_columns:\n",
    "    app_df = app_df.withColumn(column, col(column).cast(\"int\"))\n",
    "\n",
    "# ตรวจสอบ schema หลังจากการแปลง\n",
    "app_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d1afbb-edda-422c-9cc0-6b4fefa3bc4a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Data Quality Check And Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99aa0e17-f895-402a-bf88-9531cd9e8942",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.1 Percentage of missing values for columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45f708d6-3202-474f-b2e6-0e8b31fdc270",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_count = app_df.count()\n",
    "\n",
    "missing_percentage_df = (app_df.select([(count(when(col(c).isNull() | isnan(c), c)) / total_count * 100).alias(c) for c in app_df.columns])\n",
    "                         .toPandas().T.rename(columns={0: 'percentage_missing_value'})\n",
    "                         .sort_values(by='percentage_missing_value', ascending=False))\n",
    "\n",
    "print(missing_percentage_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1939808-6fba-484a-b602-75ac984ad50c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#สรุปเปอร์เซ็นต์ของค่าที่ขาด\n",
    "no_missing = (100.0 * missing_percentage_df[missing_percentage_df['percentage_missing_value'] == 0].count() / len(missing_percentage_df)).round(2)\n",
    "low_missing = (100.0 * missing_percentage_df[(missing_percentage_df['percentage_missing_value'] > 0) & (missing_percentage_df['percentage_missing_value'] <= 10)].count() / len(missing_percentage_df)).round(2)\n",
    "mid_missing = (100.0 * missing_percentage_df[(missing_percentage_df['percentage_missing_value'] > 10) & (missing_percentage_df['percentage_missing_value'] <= 50)].count() / len(missing_percentage_df)).round(2)\n",
    "high_missing = (100.0 * missing_percentage_df[missing_percentage_df['percentage_missing_value'] > 50].count() / len(missing_percentage_df)).round(2)\n",
    "\n",
    "# Print the summary\n",
    "print(f\"{no_missing[0]}% columns have no missing value\")\n",
    "print(f\"{low_missing[0]}% columns have missing value between 0-10%\")\n",
    "print(f\"{mid_missing[0]}% columns have missing value between 10-50%\")\n",
    "print(f\"{high_missing[0]}% columns have more than 50% missing value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "150ccd29-dd1f-445b-93d8-e55cf1da8c5d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- คอลัมน์ที่ไม่มีค่า missing (0% missing): จำนวนและเปอร์เซ็นต์ของคอลัมน์ที่ไม่มีค่าขาดหายไปเลย (มีข้อมูลครบถ้วนทั้งหมด)\n",
    "- คอลัมน์ที่มีค่า missing ในช่วง 0-10%: จำนวนและเปอร์เซ็นต์ของคอลัมน์ที่มีค่าขาดหายไปเล็กน้อย (อยู่ระหว่าง 0-10%)\n",
    "- คอลัมน์ที่มีค่า missing ในช่วง 10-50%: จำนวนและเปอร์เซ็นต์ของคอลัมน์ที่มีค่าขาดหายไปปานกลาง (อยู่ระหว่าง 10-50%)\n",
    "- คอลัมน์ที่มีค่า missing มากกว่า 50%: จำนวนและเปอร์เซ็นต์ของคอลัมน์ที่มีค่าขาดหายไปมากกว่า 50% ซึ่งแสดงถึงการขาดหายไปของข้อมูลในระดับสูง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a33d421-e0ef-4a5d-8d16-f8e550f26017",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### checking row-wise null percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24012085-3d82-4a1a-bfdb-f13042f1fd37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# checking row-wise null percentages\n",
    "\n",
    "# สร้างคอลัมน์ใหม่ 'num_missing_value' เพื่อเก็บจำนวนค่าที่ขาดหายไปในแต่ละแถว\n",
    "row_null = app_df.withColumn(\n",
    "    'num_missing_value', \n",
    "    sum(when(col(c).isNull(), 1).otherwise(0) for c in app_df.columns)\n",
    ")\n",
    "\n",
    "# แสดงผลคอลัมน์ 'num_missing_value'\n",
    "row_null.select('num_missing_value').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acb3d8d3-c02d-471e-a733-ea6a6e49f68e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.2 Removing the columns with high percentage of missing values(>50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cbce9b4-538d-46d9-bd6c-d8fcaa966dce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# จำนวนแถวทั้งหมดใน DataFrame\n",
    "total_count = app_df.count()\n",
    "\n",
    "# คำนวณเปอร์เซ็นต์ของค่าที่ขาดหายไปในแต่ละคอลัมน์\n",
    "cols_to_drop = [c for c in app_df.columns if (app_df.filter(col(c).isNull()).count() / total_count * 100) > 50]\n",
    "\n",
    "# ลบคอลัมน์ที่มีค่าที่ขาดหายไปมากกว่า 50%\n",
    "app_df_1 = app_df.drop(*cols_to_drop)\n",
    "\n",
    "# แสดงคอลัมน์ที่เหลือ\n",
    "print(app_df_1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47df973b-f1ad-4ff3-8cd3-7485fd2baea5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### re-checking columns with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81b66ac-3ead-44b2-995c-163ed622f786",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# จำนวนแถวทั้งหมดใน DataFrame\n",
    "total_count = app_df_1.count()\n",
    "\n",
    "# คำนวณเปอร์เซ็นต์ของค่าที่ขาดหายไปในแต่ละคอลัมน์ แล้วเรียงลำดับ\n",
    "missing_percentage = (app_df_1.select([(count(when(col(c).isNull() | isnan(c), c)) / total_count * 100).alias(c) for c in app_df_1.columns])\n",
    "                      .toPandas().T.rename(columns={0: 'percentage_missing_value'})\n",
    "                      .sort_values(by='percentage_missing_value', ascending=True))\n",
    "\n",
    "# แสดงผล\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f9fce3f-c2ce-4206-aea4-42abad5e370e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.3 Checking the data type of columns and fixing the incorrect data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af9e8477-8c1b-4407-ac69-37aa0402fb1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#checking the data types to identify the incorrect data type\n",
    "app_df_1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db4a4f55-59ea-4d72-ae6a-e657a3b0e2cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### We did not find any column with incorrect data types. Each categorical column is of type object and each numerical column is either of float or int type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64172c23-bc07-41d8-9708-092f5c3ed25b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, abs as pyspark_abs, round as pyspark_round\n",
    "\n",
    "# แปลงหน่วยจากวันเป็นปี (โดยการหารด้วย 365) และแปลงเป็นค่าบวก\n",
    "app_df_1 = app_df.withColumn('DAYS_BIRTH', pyspark_round(pyspark_abs(col('DAYS_BIRTH') / 365), 2)) \\\n",
    "                 .withColumn('DAYS_EMPLOYED', pyspark_round(pyspark_abs(col('DAYS_EMPLOYED') / 365), 2)) \\\n",
    "                 .withColumn('DAYS_REGISTRATION', pyspark_round(pyspark_abs(col('DAYS_REGISTRATION') / 365), 2)) \\\n",
    "                 .withColumn('DAYS_ID_PUBLISH', pyspark_round(pyspark_abs(col('DAYS_ID_PUBLISH') / 365), 2)) \\\n",
    "                 .withColumn('DAYS_LAST_PHONE_CHANGE', pyspark_round(pyspark_abs(col('DAYS_LAST_PHONE_CHANGE') / 365), 2))\n",
    "\n",
    "# แสดงผลลัพธ์ของ DataFrame ที่แก้ไขแล้ว\n",
    "app_df_1.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bddf4342-65f9-4c30-a2af-e2bfed7ad810",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.4 Identifying Outliers for Numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70b0e56c-2f07-4f7b-ad55-26e0ecf5183a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### For the outlier analysis of numerical columns, we will focus on\n",
    "- AMT_GOODS_PRICE\n",
    "- AMT_INCOME_TOTAL\n",
    "- AMT_CREDIT\n",
    "- AMT_ANNUITY\n",
    "- FLOORSMAX_AVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13795c33-8ce8-42d2-9a5f-c10cfb32595f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.4.1 Outlier analysis for AMT_GOODS_PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "508d8117-e29e-455e-b9e3-972c9313728e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_df_1_pandas = app_df_1.select('AMT_GOODS_PRICE').toPandas()\n",
    "\n",
    "sns.boxplot(app_df_1_pandas['AMT_GOODS_PRICE'] / 1000.0)\n",
    "plt.xlabel('AMT_GOODS_PRICE (in 000s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb729c09-1d43-4649-8dfa-dc26247529c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# คำนวณสถิติสำหรับคอลัมน์ AMT_GOODS_PRICE โดยแบ่งค่าด้วย 1000\n",
    "app_df_1.select((col('AMT_GOODS_PRICE') / 1000).alias('AMT_GOODS_PRICE_in_1000')).describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb5f20c-a85b-4cf0-b599-c8a397f8c9ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# คำนวณควอร์ไทล์ที่ 1 (25%) และควอร์ไทล์ที่ 3 (75%)\n",
    "quantiles = app_df_1.approxQuantile('AMT_GOODS_PRICE', [0.25, 0.75], 0.05)\n",
    "\n",
    "# คำนวณ IQR (Interquartile Range)\n",
    "IQR_AMT_GOODS_PRICE = (quantiles[1] - quantiles[0]) / 1000\n",
    "\n",
    "# คำนวณ Upper Limit สำหรับ boxplot\n",
    "Upper_limit_IQR_AMT_GOODS_PRICE = (quantiles[1] / 1000) + IQR_AMT_GOODS_PRICE * 1.5\n",
    "\n",
    "Upper_limit_IQR_AMT_GOODS_PRICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d8654f6-0ad6-4449-919a-b010a8b8f066",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# กรองแถวที่มีค่า AMT_GOODS_PRICE มากกว่า Upper_limit_IQR_AMT_GOODS_PRICE\n",
    "outliers_count = app_df_1.filter((col('AMT_GOODS_PRICE') / 1000) > Upper_limit_IQR_AMT_GOODS_PRICE).count()\n",
    "\n",
    "# จำนวนแถวทั้งหมดใน DataFrame\n",
    "total_count = app_df_1.count()\n",
    "\n",
    "# คำนวณเปอร์เซ็นต์ของค่าผิดปกติ (outliers)\n",
    "percentage_outliers = round(100.0 * outliers_count / total_count, 2)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "percentage_outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ff0dc97-7d60-4228-91c8-3f0552f3bbfa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " From the boxplot, we can see there are outliers in AMT_GOODS_PRICE. The percentage of outliers stands at 4.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c642dc68-4f7c-4720-894c-a76d6d94de6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Outlier   ของ AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \"AMT_ANNUITY\", \"FLOORSMAX_AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30777ab9-4f05-4836-8df4-c8c48e86b1d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# แปลง PySpark DataFrame เป็น Pandas DataFrame\n",
    "app_df_1_pandas = app_df_1.select(\"AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \"AMT_ANNUITY\", \"FLOORSMAX_AVG\").toPandas()\n",
    "\n",
    "# สร้าง boxplot สำหรับแต่ละคอลัมน์\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# สร้าง subplot สำหรับแต่ละคอลัมน์\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(y=app_df_1_pandas['AMT_INCOME_TOTAL'] / 1000)\n",
    "plt.title('AMT_INCOME_TOTAL (in 000s)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(y=app_df_1_pandas['AMT_CREDIT'] / 1000)\n",
    "plt.title('AMT_CREDIT (in 000s)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(y=app_df_1_pandas['AMT_ANNUITY'] / 1000)\n",
    "plt.title('AMT_ANNUITY (in 000s)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(y=app_df_1_pandas['FLOORSMAX_AVG'])\n",
    "plt.title('FLOORSMAX_AVG')\n",
    "\n",
    "# แสดงผล\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c58e8dcd-90cd-48d7-860f-88cd44247701",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ฟังก์ชันคำนวณ IQR และ Upper Limit สำหรับแต่ละคอลัมน์\n",
    "def calculate_upper_limit(df, column):\n",
    "    quantiles = df.approxQuantile(column, [0.25, 0.75], 0.05)  # คำนวณ Q1 และ Q3\n",
    "    IQR = quantiles[1] - quantiles[0]  # คำนวณ IQR\n",
    "    upper_limit = quantiles[1] + 1.5 * IQR  # คำนวณ Upper Limit\n",
    "    return upper_limit\n",
    "\n",
    "# คำนวณ Upper Limit สำหรับแต่ละคอลัมน์\n",
    "upper_limit_income = calculate_upper_limit(app_df_1, 'AMT_INCOME_TOTAL')\n",
    "upper_limit_credit = calculate_upper_limit(app_df_1, 'AMT_CREDIT')\n",
    "upper_limit_annuity = calculate_upper_limit(app_df_1, 'AMT_ANNUITY')\n",
    "upper_limit_floorsmax = calculate_upper_limit(app_df_1, 'FLOORSMAX_AVG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec06f675-1649-4dcd-9b17-915111147c11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ฟังก์ชันคำนวณจำนวนและเปอร์เซ็นต์ของ outliers\n",
    "def calculate_outliers_percentage(df, column, upper_limit):\n",
    "    outliers_count = df.filter(col(column) > upper_limit).count()  # กรองค่าที่เป็น outliers\n",
    "    total_count = df.count()  # จำนวนแถวทั้งหมด\n",
    "    percentage_outliers = round(100.0 * outliers_count / total_count, 2)  # คำนวณเปอร์เซ็นต์\n",
    "    return percentage_outliers\n",
    "\n",
    "# คำนวณเปอร์เซ็นต์ของ outliers สำหรับแต่ละคอลัมน์\n",
    "outliers_income = calculate_outliers_percentage(app_df_1, 'AMT_INCOME_TOTAL', upper_limit_income)\n",
    "outliers_credit = calculate_outliers_percentage(app_df_1, 'AMT_CREDIT', upper_limit_credit)\n",
    "outliers_annuity = calculate_outliers_percentage(app_df_1, 'AMT_ANNUITY', upper_limit_annuity)\n",
    "outliers_floorsmax = calculate_outliers_percentage(app_df_1, 'FLOORSMAX_AVG', upper_limit_floorsmax)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(f\"Outliers percentage for AMT_INCOME_TOTAL: {outliers_income}%\")\n",
    "print(f\"Outliers percentage for AMT_CREDIT: {outliers_credit}%\")\n",
    "print(f\"Outliers percentage for AMT_ANNUITY: {outliers_annuity}%\")\n",
    "print(f\"Outliers percentage for FLOORSMAX_AVG: {outliers_floorsmax}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4719f5c-e8c5-40e9-a7d4-096825886ff9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- AMT_INCOME_TOTAL: มีค่าผิดปกติ 4.56% ซึ่งแสดงถึงกลุ่มข้อมูลรายได้ที่ค่อนข้างสูงหรือต่ำผิดปกติเมื่อเทียบกับข้อมูลส่วนใหญ่\n",
    "- AMT_CREDIT: มีค่าผิดปกติ 3.55% ซึ่งบ่งชี้ว่ามีจำนวนเล็กน้อยของผู้กู้ที่มีวงเงินสินเชื่อที่ผิดปกติเมื่อเทียบกับคนอื่น ๆ\n",
    "- AMT_ANNUITY: มีค่าผิดปกติ 3.61% ซึ่งหมายถึงจำนวนเงินงวดการชำระต่อปีที่มีค่าแตกต่างจากกลุ่มข้อมูลหลัก\n",
    "- FLOORSMAX_AVG: มีค่าผิดปกติ 1.7% ซึ่งบ่งบอกถึงจำนวนชั้นสูงสุดของอาคารที่แตกต่างจากกลุ่มข้อมูลทั่วไป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a495ac9-0207-4e89-9090-8bfb54674b33",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Binning of continuous Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31bf7bf8-4e54-467a-8223-16e0f9d30035",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " For the binning, we will use following columns\n",
    "- AGE_GROUP\n",
    "- AMT_CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4589aba-68ab-4d9d-b9a1-b811ca29195f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_df_1.select(\"DAYS_BIRTH\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2f3db3f-72c2-45cd-81b6-ea013bdd2934",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# แบ่งช่วงอายุ (AGE_GROUP) โดยตรงจากค่าของ DAYS_BIRTH (ที่เป็นจำนวนปีอยู่แล้ว)\n",
    "app_df_1 = app_df_1.withColumn(\n",
    "    \"AGE_GROUP\", \n",
    "    when(col(\"DAYS_BIRTH\").between(0, 19), \"10s\")\n",
    "    .when(col(\"DAYS_BIRTH\").between(20, 29), \"20s\")\n",
    "    .when(col(\"DAYS_BIRTH\").between(30, 39), \"30s\")\n",
    "    .when(col(\"DAYS_BIRTH\").between(40, 49), \"40s\")\n",
    "    .when(col(\"DAYS_BIRTH\").between(50, 59), \"50s\")\n",
    "    .when(col(\"DAYS_BIRTH\").between(60, 69), \"60s\")\n",
    "    .when(col(\"DAYS_BIRTH\").between(70, 79), \"70s\")\n",
    "    .when(col(\"DAYS_BIRTH\").between(80, 89), \"80s\")\n",
    "    .otherwise(\"Unknown\")\n",
    ")\n",
    "\n",
    "# คำนวณจำนวนแถวในแต่ละกลุ่มอายุ และเรียงลำดับจากมากไปน้อย\n",
    "age_group_counts = app_df_1.groupBy(\"AGE_GROUP\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "age_group_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "219cbae4-c4ba-4e52-8ba5-03d2a9741eca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# แบ่งช่วงของ AMT_INCOME_TOTAL และสร้างคอลัมน์ใหม่ AMT_CATEGORY\n",
    "app_df_1 = app_df_1.withColumn(\n",
    "    \"AMT_CATEGORY\", \n",
    "    when(col(\"AMT_INCOME_TOTAL\").between(0, 100000), \"Low\")\n",
    "    .when(col(\"AMT_INCOME_TOTAL\").between(100001, 200000), \"Average\")\n",
    "    .when(col(\"AMT_INCOME_TOTAL\").between(200001, 300000), \"Good\")\n",
    "    .when(col(\"AMT_INCOME_TOTAL\").between(300001, 400000), \"Best\")\n",
    "    .when(col(\"AMT_INCOME_TOTAL\").between(400001, 500000), \"High\")\n",
    "    .when(col(\"AMT_INCOME_TOTAL\").between(500001, 600000), \"Very High\")\n",
    "    .otherwise(\"Unknown\")\n",
    ")\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "app_df_1.select(\"AMT_INCOME_TOTAL\", \"AMT_CATEGORY\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956f07f4-eafe-4eae-b6c4-cb7be67cee0a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e21e53e4-1471-4020-b8e0-6b959b37a8ce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "ในการวิเคราะห์เพิ่มเติม เราจะลบคอลัมน์ที่ไม่เกี่ยวข้องออก และดำเนินการวิเคราะห์ต่อด้วยคอลัมน์ที่เลือกไว้เพียงไม่กี่คอลัมน์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2120fe7-a249-49f3-b944-c2712bc28420",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# list of columns to be dropped\n",
    "drop_columns = ['FLAG_CONT_MOBILE',\n",
    "                'FLAG_MOBIL',\n",
    "                'FLAG_EMP_PHONE',\n",
    "                'FLAG_WORK_PHONE',\n",
    "                'FLAG_PHONE',\n",
    "                'FLAG_EMAIL',\n",
    "                'HOUR_APPR_PROCESS_START',\n",
    "                'WEEKDAY_APPR_PROCESS_START',\n",
    "                'FLOORSMAX_AVG',\n",
    "                'EXT_SOURCE_2',\n",
    "                'EXT_SOURCE_3',\n",
    "                'FLOORSMAX_AVG',\n",
    "                'FLOORSMAX_MODE',\n",
    "                'FLOORSMAX_MEDI',\n",
    "                'TOTALAREA_MODE',\n",
    "                'EMERGENCYSTATE_MODE',\n",
    "                'REGION_POPULATION_RELATIVE',\n",
    "                'YEARS_BEGINEXPLUATATION_AVG',\n",
    "                'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "                'YEARS_BEGINEXPLUATATION_MODE',\n",
    "                'REG_REGION_NOT_LIVE_REGION',\n",
    "                'REG_REGION_NOT_WORK_REGION',\n",
    "                'LIVE_REGION_NOT_WORK_REGION',\n",
    "                'REG_CITY_NOT_LIVE_CITY',\n",
    "                'REG_CITY_NOT_WORK_CITY',\n",
    "                'LIVE_CITY_NOT_WORK_CITY',\n",
    "                'FLAG_DOCUMENT_2',\n",
    "                'FLAG_DOCUMENT_3',\n",
    "                'FLAG_DOCUMENT_4',\n",
    "                'FLAG_DOCUMENT_5',\n",
    "                'FLAG_DOCUMENT_6',\n",
    "                'FLAG_DOCUMENT_7',\n",
    "                'FLAG_DOCUMENT_8',\n",
    "                'FLAG_DOCUMENT_9',\n",
    "                'FLAG_DOCUMENT_10',\n",
    "                'FLAG_DOCUMENT_11',\n",
    "                'FLAG_DOCUMENT_12',\n",
    "                'FLAG_DOCUMENT_13',\n",
    "                'FLAG_DOCUMENT_14',\n",
    "                'FLAG_DOCUMENT_15',\n",
    "                'FLAG_DOCUMENT_16',\n",
    "                'FLAG_DOCUMENT_17',\n",
    "                'FLAG_DOCUMENT_18',\n",
    "                'FLAG_DOCUMENT_19',\n",
    "                'FLAG_DOCUMENT_20',\n",
    "                'FLAG_DOCUMENT_21'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "934ad599-5e22-40c5-a7dc-39610dec20d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_df_2 = app_df_1.drop(*drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bda96095-4a44-4afe-b521-45efe310009a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_df_2.display(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f15b1082-b326-4892-8b81-e7eaf958c8a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_count = app_df_2.count()\n",
    "\n",
    "# คำนวณเปอร์เซ็นต์ของค่าที่ขาดหายไปและเรียงลำดับ\n",
    "missing_percentage_df = (app_df_2.select([(count(when(col(c).isNull() | isnan(c), c)) / total_count * 100).alias(c) for c in app_df_2.columns])\n",
    "                         .toPandas().T.rename(columns={0: 'percentage_missing_value'})\n",
    "                         .sort_values(by='percentage_missing_value'))\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(missing_percentage_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82c8c73d-810c-46be-a07a-f99e4442d5c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3.1 Checking imbalance in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f81004f-9e1b-4d11-8b80-c8246c794580",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# คำนวณจำนวนคนที่ไม่มีหนี้สินคงค้าง (TARGET == 0)\n",
    "target_0_count = app_df_2.filter(col(\"TARGET\") == 0).count()\n",
    "\n",
    "# คำนวณจำนวนคนที่มีหนี้สินคงค้าง (TARGET == 1)\n",
    "target_1_count = app_df_2.filter(col(\"TARGET\") == 1).count()\n",
    "\n",
    "# คำนวณจำนวนทั้งหมดใน DataFrame\n",
    "total_count = app_df_2.count()\n",
    "\n",
    "# คำนวณเปอร์เซ็นต์ของ TARGET == 0 และ TARGET == 1\n",
    "target_0_percentage = round((target_0_count / total_count) * 100, 2)\n",
    "target_1_percentage = round((target_1_count / total_count) * 100, 2)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(f\"Target_0_percentage: {target_0_percentage}%\")\n",
    "print(f\"Target_1_percentage: {target_1_percentage}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "858aa88d-f772-4604-9ac6-6126b39df94e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# คำนวณจำนวนคนที่ไม่มีหนี้สินคงค้าง (TARGET == 0)\n",
    "target_0_count = app_df_2.filter(col(\"TARGET\") == 0).count()\n",
    "\n",
    "# คำนวณจำนวนคนที่มีหนี้สินคงค้าง (TARGET == 1)\n",
    "target_1_count = app_df_2.filter(col(\"TARGET\") == 1).count()\n",
    "\n",
    "# สร้างข้อมูลสำหรับการ plot\n",
    "data = {\n",
    "    'Target': ['No Default (TARGET == 0)', 'Default (TARGET == 1)'],\n",
    "    'Count': [target_0_count, target_1_count]\n",
    "}\n",
    "\n",
    "# สร้าง DataFrame สำหรับการ visualize\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# สร้างกราฟ bar plot สำหรับจำนวนของ TARGET == 0 และ TARGET == 1\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Target', y='Count', data=df)\n",
    "plt.title('Count of No Default vs Default')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70841146-f892-4c83-9dda-9e0d2ee44f38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.1.1 Creating Target_0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c446162-8cfb-43f1-ab22-fb865e0906f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# กรองข้อมูลที่ TARGET == 0 (non-defaulters)\n",
    "target_0_df = app_df_2.filter(col(\"TARGET\") == 0)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "target_0_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e5a708a-156d-46c6-9fb5-26ce2844570c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating Target_1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b68db308-be74-49b7-910a-8cac3500e042",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49469e31-f5c8-4a18-99c9-1833c7966e3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# กรองข้อมูลที่ TARGET == 0 (non-defaulters)\n",
    "target_1_df = app_df_2.filter(col(\"TARGET\") == 1)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "target_1_df.display(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c308bda0-2aa0-4319-b17a-1c12a132a2c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Defind cat or num cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d511af-fdc3-48a0-8a8d-4eaf9cd71b16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#list of all categorical columns\n",
    "categorical_columns = ['NAME_CONTRACT_TYPE',\n",
    "                       'FLAG_OWN_CAR',\n",
    "                       'FLAG_OWN_REALTY',\n",
    "                       'CODE_GENDER',\n",
    "                       'NAME_EDUCATION_TYPE',\n",
    "                       'AMT_CATEGORY',\n",
    "                       'AGE_GROUP',\n",
    "                       'NAME_FAMILY_STATUS',\n",
    "                       'NAME_HOUSING_TYPE',\n",
    "                       'NAME_TYPE_SUITE',\n",
    "                       'NAME_INCOME_TYPE',\n",
    "                       'OCCUPATION_TYPE',\n",
    "                       'ORGANIZATION_TYPE',                       \n",
    "                       'REGION_RATING_CLIENT_W_CITY',\n",
    "                       'REGION_RATING_CLIENT',\n",
    "                       'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                       'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "                       'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                       'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "                       'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "                       'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "                       'CNT_CHILDREN',\n",
    "                       'CNT_FAM_MEMBERS',\n",
    "                       'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "                       'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "                       'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "                       'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "                      ]\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b09a14a5-5f6c-487a-ae40-b386ff0f2897",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# list of all continuous numerical column\n",
    "numerical_columns= ['AMT_GOODS_PRICE',\n",
    "                    'DAYS_LAST_PHONE_CHANGE',\n",
    "                    'DAYS_ID_PUBLISH',\n",
    "                    'AMT_INCOME_TOTAL',\n",
    "                    'DAYS_EMPLOYED',\n",
    "                    'DAYS_REGISTRATION',\n",
    "                    'DAYS_BIRTH',\n",
    "                    'AMT_CREDIT',\n",
    "                    'AMT_ANNUITY'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c00036b-150b-4c1c-bdc6-bf501cec5047",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3.2 Univariate Analysis for categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d520272-5d8a-4b0c-8cb7-a94e015f28dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loop สำหรับการวิเคราะห์ univariate analysis ของคอลัมน์เชิงหมวดหมู่\n",
    "for i in categorical_columns:\n",
    "    # สำหรับ TARGET = 0 (non-defaulters)\n",
    "    target_0_df_pandas = target_0_df.groupBy(i).agg({'*': 'count'}).toPandas()\n",
    "    # แทนที่ค่าที่เป็น None ด้วย 'Unknown' หรือค่าอื่นที่เหมาะสม\n",
    "    target_0_df_pandas[i] = target_0_df_pandas[i].fillna('Unknown')\n",
    "    target_0_df_pandas['percentage'] = target_0_df_pandas['count(1)'] / target_0_df.count() * 100\n",
    "\n",
    "    # สำหรับ TARGET = 1 (defaulters)\n",
    "    target_1_df_pandas = target_1_df.groupBy(i).agg({'*': 'count'}).toPandas()\n",
    "    # แทนที่ค่าที่เป็น None ด้วย 'Unknown' หรือค่าอื่นที่เหมาะสม\n",
    "    target_1_df_pandas[i] = target_1_df_pandas[i].fillna('Unknown')\n",
    "    target_1_df_pandas['percentage'] = target_1_df_pandas['count(1)'] / target_1_df.count() * 100\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot สำหรับ TARGET = 0\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(target_0_df_pandas[i], target_0_df_pandas['percentage'])\n",
    "    plt.title(i + ' - Target = 0')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Plot สำหรับ TARGET = 1\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(target_1_df_pandas[i], target_1_df_pandas['percentage'])\n",
    "    plt.title(i + ' - Target = 1')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # ปรับการจัด layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff0ed75e-6ea1-413c-b25d-6e123375a4a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Key interpretation from univariate analysis of Categorical variables\n",
    "  \n",
    "\n",
    "- Code_Gender: ลูกค้าที่เป็นผู้ชายมีเปอร์เซ็นต์ของผู้ที่ผิดนัดชำระหนี้ (Target = 1) สูงกว่าผู้ที่ไม่ผิดนัดชำระหนี้ (Target = 0)\n",
    "- NAME_EDUCATION_TYPE: ลูกค้าที่มีการศึกษาระดับมัธยมปลายหรือมัธยมศึกษาพิเศษ (Secondary/Secondat Special education) มีเปอร์เซ็นต์ของผู้ผิดนัดชำระหนี้ (Target = 1) สูงกว่ากลุ่มที่ไม่ผิดนัดชำระหนี้\n",
    "- Age_Group: กลุ่มอายุที่มีเปอร์เซ็นต์ของผู้ผิดนัดชำระหนี้สูงที่สุดคือกลุ่มอายุ 30 ปี (30s)\n",
    "- NAME_INCOME_TYPE: ลูกค้าที่มีอาชีพหลักคือการทำงานมีเปอร์เซ็นต์ของผู้ผิดนัดชำระหนี้สูงกว่ากลุ่มลูกค้าที่เป็นผู้รับบำนาญ ซึ่งกลุ่มลูกค้าผู้รับบำนาญมีอัตราการผิดนัดชำระหนี้ต่ำกว่าในกลุ่มลูกค้าที่ไม่ผิดนัดชำระหนี้\n",
    "- OCCUPATION_TYPE: ลูกค้าที่ประกอบอาชีพกรรมกรมีเปอร์เซ็นต์ของการผิดนัดชำระหนี้ (Target = 1) สูงกว่าลูกค้าในกลุ่มที่ไม่ผิดนัดชำระหนี้\n",
    "- REGION_RATING_CLIENT_W_CITY: ลูกค้าที่มีคะแนนระดับ 3 (จากระบบการจัดอันดับภูมิภาค) มีเปอร์เซ็นต์ของการผิดนัดชำระหนี้สูงกว่าลูกค้าในกลุ่มที่ไม่ผิดนัดชำระหนี้\n",
    "- REGION_RATING_CLIENT: ลูกค้าที่มีคะแนนระดับ 3 มีเปอร์เซ็นต์ของการผิดนัดชำระหนี้สูงกว่ากลุ่มลูกค้าที่ไม่ผิดนัดชำระหนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3c32006-ce4a-4782-8b45-97c0d7e91a7d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3.3 Correlation for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22683ac1-a544-4553-872c-169b10e2c081",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# สร้าง DataFrame ของคอลัมน์เชิงตัวเลข (numerical columns)\n",
    "numerical_df = app_df_2.select(numerical_columns)\n",
    "\n",
    "# คำนวณความสัมพันธ์สำหรับแต่ละคู่ของคอลัมน์เชิงตัวเลข\n",
    "correlation_matrix = pd.DataFrame({col: [numerical_df.stat.corr(col, c) for c in numerical_columns] for col in numerical_columns}, index=numerical_columns)\n",
    "\n",
    "# สร้าง heatmap โดยใช้ seaborn\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "\n",
    "# ปรับค่าขอบเขตของกราฟเพื่อให้แสดงผลอย่างถูกต้อง\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t)\n",
    "\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c7510be-7463-46fc-9964-37508c12b6c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# คำนวณ correlation matrix สำหรับ TARGET = 0\n",
    "numerical_df_0 = target_0_df.select(numerical_columns)\n",
    "correlation_matrix_0 = pd.DataFrame({col: [numerical_df_0.stat.corr(col, c) for c in numerical_columns] for col in numerical_columns}, index=numerical_columns)\n",
    "\n",
    "# คำนวณ correlation matrix สำหรับ TARGET = 1\n",
    "numerical_df_1 = target_1_df.select(numerical_columns)\n",
    "correlation_matrix_1 = pd.DataFrame({col: [numerical_df_1.stat.corr(col, c) for c in numerical_columns] for col in numerical_columns}, index=numerical_columns)\n",
    "\n",
    "# สร้าง heatmap สำหรับ TARGET = 0 และ TARGET = 1\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Heatmap สำหรับ TARGET = 0\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(correlation_matrix_0, annot=True)\n",
    "plt.title('heatmap - Target = 0')\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Heatmap สำหรับ TARGET = 1\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(correlation_matrix_1, annot=True)\n",
    "plt.title('heatmap - Target = 1')\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# แสดงผล\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13763e5a-37cd-4cc1-9b08-fed8462de60c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3.4 Checking if Variables with highest coeffecient are same in both file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e5062a-5caf-4593-bea1-098bc94c20bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# คำนวณ correlation matrix สำหรับ TARGET = 0\n",
    "numerical_df_0 = target_0_df.select(numerical_columns)\n",
    "correlation_matrix_0 = pd.DataFrame({col: [numerical_df_0.stat.corr(col, c) for c in numerical_columns] for col in numerical_columns}, index=numerical_columns)\n",
    "\n",
    "# คำนวณ correlation matrix สำหรับ TARGET = 1\n",
    "numerical_df_1 = target_1_df.select(numerical_columns)\n",
    "correlation_matrix_1 = pd.DataFrame({col: [numerical_df_1.stat.corr(col, c) for c in numerical_columns] for col in numerical_columns}, index=numerical_columns)\n",
    "\n",
    "# หา correlation ที่มีค่าสูงสุดสำหรับ TARGET = 0\n",
    "max_corr_0 = correlation_matrix_0.abs().unstack().sort_values(ascending=False).drop_duplicates().idxmax()\n",
    "\n",
    "# หา correlation ที่มีค่าสูงสุดสำหรับ TARGET = 1\n",
    "max_corr_1 = correlation_matrix_1.abs().unstack().sort_values(ascending=False).drop_duplicates().idxmax()\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(f\"ตัวแปรที่มีค่าสัมประสิทธิ์สูงสุดใน TARGET = 0: {max_corr_0}\")\n",
    "print(f\"ตัวแปรที่มีค่าสัมประสิทธิ์สูงสุดใน TARGET = 1: {max_corr_1}\")\n",
    "\n",
    "# ตรวจสอบว่าตัวแปรที่มีค่าสูงสุดเหมือนกันหรือไม่\n",
    "if max_corr_0 == max_corr_1:\n",
    "    print(\"ตัวแปรที่มีค่าสัมประสิทธิ์สูงสุดในทั้งสองกลุ่มเหมือนกัน\")\n",
    "else:\n",
    "    print(\"ตัวแปรที่มีค่าสัมประสิทธิ์สูงสุดในทั้งสองกลุ่มแตกต่างกัน\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a215b2b-9622-42ea-9713-e6b7aad91fa0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3.5 Univariate Analysis for Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00519699-2128-4d30-90f2-2929e2fd3757",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loop สำหรับการสร้าง boxplot สำหรับแต่ละคอลัมน์เชิงตัวเลข\n",
    "for i in numerical_columns:\n",
    "    # แปลง DataFrame เป็น Pandas DataFrame\n",
    "    target_0_df_pandas = target_0_df.select(i).toPandas()\n",
    "    target_1_df_pandas = target_1_df.select(i).toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Boxplot สำหรับ TARGET = 0\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(target_0_df_pandas[i])\n",
    "    plt.title(i + ' - Target = 0')\n",
    "\n",
    "    # Boxplot สำหรับ TARGET = 1\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(target_1_df_pandas[i])\n",
    "    plt.title(i + ' - Target = 1')\n",
    "\n",
    "    # แสดงผล\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e6d1283-df1b-4cbf-8554-07bec57dbcd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## The objective of this analysis is to find pattern in defaulter vs non-defaulter customers wrt target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "100140c5-7036-42e5-8e9e-2d66243fa7cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loop สำหรับการวิเคราะห์ bivariate analysis ของตัวแปรเชิงตัวเลข\n",
    "for i in numerical_columns:\n",
    "    # แปลง PySpark DataFrame เป็น Pandas DataFrame ก่อน\n",
    "    app_df_pandas = app_df_2.select('TARGET', i).toPandas()\n",
    "\n",
    "    # สร้างกราฟ boxplot โดยใช้ Seaborn\n",
    "    sns.boxplot(data=app_df_pandas, x='TARGET', y=i)\n",
    "    \n",
    "    # แสดงกราฟ\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d5f600-e61b-4383-a621-273c68eb2599",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "การตีความที่สำคัญจากการวิเคราะห์เชิงเดี่ยวของตัวแปรเชิงตัวเลข\n",
    "ในส่วนนี้ เราจะเน้นเฉพาะตัวแปรที่มีความแตกต่างอย่างมีนัยสำคัญระหว่างกลุ่ม target = 0 และ target = 1\n",
    "- DAYS_LAST_PHONE_CHANGE: ค่ามัธยฐานและเปอร์เซ็นไทล์ที่ 75 ของกลุ่มผู้ผิดนัดชำระหนี้ (Target = 1) ต่ำกว่ากลุ่มที่ไม่ผิดนัดชำระหนี้  -   - ซึ่งหมายความว่าผู้ผิดนัดชำระหนี้มีแนวโน้มที่จะเปลี่ยนหมายเลขโทรศัพท์บ่อยขึ้นก่อนที่จะทำการสมัคร\n",
    "- DAYS_ID_PUBLISH: ผู้ผิดนัดชำระหนี้ดูเหมือนจะเปลี่ยนรหัสประจำตัวบ่อยกว่าผู้ที่ไม่ผิดนัดชำระหนี้\n",
    "- DAYS_BIRTH: ค่าเปอร์เซ็นไทล์ที่ 25 ค่ามัธยฐาน และเปอร์เซ็นไทล์ที่ 75 สำหรับอายุของผู้สมัครที่เป็นผู้ผิดนัดชำระหนี้น้อยกว่าผู้สมัครที่อายุน้อยกว่า ซึ่งหมายความว่ากลุ่มผู้ผิดนัดชำระหนี้มีแนวโน้มที่จะเป็นคนอายุน้อยกว่ากลุ่มที่ไม่ผิดนัดชำระหนี้\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2134419e-ab3f-4f72-b11c-1bab9e290ac6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3.6 Bivariate Analysis for Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba0712fd-df12-49d5-afad-548f8b4a88e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loop สำหรับการสร้าง bar plot สำหรับแต่ละคอลัมน์เชิงหมวดหมู่\n",
    "for i in categorical_columns:\n",
    "    # คำนวณค่าเฉลี่ยของ TARGET สำหรับแต่ละค่าในคอลัมน์เชิงหมวดหมู่\n",
    "    mean_target_df = app_df_2.groupBy(i).agg({'TARGET': 'mean'}).toPandas()\n",
    "\n",
    "    # สร้าง bar plot\n",
    "    mean_target_df.plot(x=i, y='avg(TARGET)', kind='bar', legend=False)\n",
    "    plt.title(i + ' vs Target')\n",
    "    plt.ylabel('Average Target')\n",
    "    \n",
    "    # แสดงผล\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ba2e9d1-ef94-456f-8599-440d8adec5fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### สรุป\n",
    "- CODE_GENDER: ลูกค้าที่เป็นผู้ชายมีความน่าจะเป็นในการผิดนัดชำระหนี้สูงกว่า\n",
    "- NAME_EDUCATION_TYPE: ลูกค้าที่มีการศึกษาระดับมัธยมศึกษาตอนต้นหรือต่ำกว่ามีความเสี่ยงต่อการผิดนัดชำระหนี้สูงกว่า\n",
    "- AGE_GROUP: ลูกค้าที่อยู่ในกลุ่มอายุ 20 และ 30 ปีมีโอกาสผิดนัดชำระหนี้สูงกว่า\n",
    "- NAME_HOUSING_TYPE: ลูกค้าที่อาศัยอยู่ในอพาร์ทเมนท์เช่าหรืออยู่กับพ่อแม่มีแนวโน้มที่จะผิดนัดชำระหนี้มากกว่า\n",
    "- NAME_INCOME_TYPE: ลูกค้าที่ว่างงานและลูกค้าที่อยู่ในช่วงลาคลอดมีความเสี่ยงสูงกว่า\n",
    "- OCCUPATION_TYPE: แรงงานทักษะต่ำมีแนวโน้มที่จะผิดนัดชำระหนี้มากกว่า\n",
    "- REGION_RATING_CLIENT และ REGION_RATING_CLIENT_W_CITY: ลูกค้าที่มีคะแนนระดับ 3 มีความเสี่ยงในการผิดนัดชำระหนี้สูงกว่า"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "938b7c07-c724-4354-b188-1be2e7d27acf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceba211a-8ad5-40e9-b292-a95dd1049feb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ตรวจสอบจำนวนค่า null ในแต่ละคอลัมน์ (ทั้งเชิงตัวเลขและหมวดหมู่)\n",
    "app_df_2.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in numerical_columns + categorical_columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d090bd89-c2c4-4a5f-abbb-f00b15aeba74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### check null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0333c688-add7-4688-b5c1-320ef515e2d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mean_value = app_df_2.select(F.mean(F.col(\"DAYS_LAST_PHONE_CHANGE\"))).collect()[0][0]\n",
    "app_df_2 = app_df_2.na.fill({\"DAYS_LAST_PHONE_CHANGE\": mean_value})\n",
    "\n",
    "# เติมค่า null ในคอลัมน์ OCCUPATION_TYPE ด้วย 'Unknown'\n",
    "app_df_2 = app_df_2.na.fill({\"OCCUPATION_TYPE\": \"Unknown\"})\n",
    "\n",
    "# ตรวจสอบผลลัพธ์หลังจากเติมค่า\n",
    "app_df_2.select(\"OCCUPATION_TYPE\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37eba25d-47b9-4884-9240-8510a86af9f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26627d93-0124-4841-8fcc-94986ec3a32f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_col =categorical_columns +numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "580aea33-2ce2-47f0-a8ff-1fea864616d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_columns = categorical_columns + numerical_columns\n",
    "\n",
    "# แสดง DataFrame ที่รวมคอลัมน์ทั้งสองชุด\n",
    "display(app_df_2.select(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5470368-e531-4361-a331-7dc1e1eef217",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "090da049-7ac0-47aa-9838-9527fbd7db54",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Encoders And Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a47d77-0355-4578-92f2-efa2d13bcd03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# แปลงคอลัมน์เชิงตัวเลขเป็นชนิด double\n",
    "app_df_2 = app_df_2.withColumn(\"DAYS_LAST_PHONE_CHANGE\", F.col(\"DAYS_LAST_PHONE_CHANGE\").cast(\"double\"))\n",
    "app_df_2 = app_df_2.withColumn(\"DAYS_ID_PUBLISH\", F.col(\"DAYS_ID_PUBLISH\").cast(\"double\"))\n",
    "\n",
    "# Categorical Columns\n",
    "categorical_columns = [\n",
    "    \"CODE_GENDER\", \"NAME_EDUCATION_TYPE\", \"AGE_GROUP\", \n",
    "    \"NAME_HOUSING_TYPE\", \"NAME_INCOME_TYPE\", \"OCCUPATION_TYPE\",\n",
    "    \"REGION_RATING_CLIENT\", \"REGION_RATING_CLIENT_W_CITY\"\n",
    "]\n",
    "\n",
    "# Numerical Columns\n",
    "numerical_columns = [\"DAYS_LAST_PHONE_CHANGE\", \"DAYS_ID_PUBLISH\"]\n",
    "\n",
    "# 1. Label Encoding (ใช้ StringIndexer)\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_Indexed\") for col in categorical_columns]\n",
    "\n",
    "# 2. One-Hot Encoding\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_Indexed\", outputCol=col + \"_Vector\") for col in categorical_columns]\n",
    "\n",
    "# 3. Scaling ข้อมูลเชิงตัวเลข\n",
    "assembler = VectorAssembler(inputCols=numerical_columns, outputCol=\"numerical_features\")\n",
    "scaler = MinMaxScaler(inputCol=\"numerical_features\", outputCol=\"scaled_numerical_features\")\n",
    "\n",
    "# 4. Combine Categorical and Numerical features\n",
    "assembler_final = VectorAssembler(\n",
    "    inputCols=[col + \"_Vector\" for col in categorical_columns] + [\"scaled_numerical_features\"], \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Apply transformations in stages\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, assembler_final])\n",
    "model = pipeline.fit(app_df_2)\n",
    "final_df = model.transform(app_df_2)\n",
    "\n",
    "# แสดงผลฟีเจอร์สุดท้าย\n",
    "final_df.select(\"features\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df0b9258-2a12-4fd6-8bcf-d6412b238eea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbd074e8-d7ae-411f-87fd-ae791eead225",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# เพิ่ม RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"TARGET\", featuresCol=\"features\")\n",
    "\n",
    "# ใช้ Pipeline เหมือนเดิม แต่เพิ่ม RandomForest เข้าไปในขั้นตอนสุดท้าย\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, assembler_final, rf])\n",
    "\n",
    "# ฝึกโมเดล\n",
    "model = pipeline.fit(app_df_2)\n",
    "\n",
    "# ทำนายผล\n",
    "predictions = model.transform(app_df_2)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "predictions.select(\"features\", \"TARGET\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34d0b674-db98-4c3b-8a78-0cbf55a55356",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###  AUC ROC BY Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "365aa4df-5fd2-4f11-98fe-b64ed8312a7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# ประเมินผลด้วย AUC-ROC\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"TARGET\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc = binary_evaluator.evaluate(predictions)\n",
    "print(f\"AUC-ROC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604d4071-f97d-4c8f-b0a4-8376488351d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions using the model (ตัวอย่าง Logistic Regression)\n",
    "predictions = lr_model.transform(final_df)\n",
    "\n",
    "# หรือในกรณีของ Decision Tree:\n",
    "# predictions = dt_model.transform(final_df)\n",
    "\n",
    "# ประเมินผลด้วย AUC-ROC\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"TARGET\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc = binary_evaluator.evaluate(predictions)\n",
    "print(f\"AUC-ROC: {roc_auc}\")\n",
    "\n",
    "# ประเมิน Accuracy และ F1 Score\n",
    "multiclass_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "accuracy = multiclass_evaluator.evaluate(predictions)\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "063d1c6c-be01-441e-b241-184839e6e0a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03ad3176-749a-4b8b-b625-76d7fd6e52c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c936c8b0-15be-48bc-afa3-56c6dc2f837b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"TARGET\", maxIter=10)\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(final_df)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.transform(final_df)\n",
    "\n",
    "# Show predictions\n",
    "lr_predictions.select(\"features\", \"TARGET\", \"prediction\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263a71cb-1fd4-4a50-af7c-cea3dbbc6179",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d0f9e21-cc9b-4112-9d1a-bbc3a338f26d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"TARGET\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "multiclass_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "\n",
    "# Logistic Regression Metrics\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "lr_auc = binary_evaluator.evaluate(lr_predictions)\n",
    "lr_accuracy = multiclass_evaluator.evaluate(lr_predictions)\n",
    "lr_f1 = f1_evaluator.evaluate(lr_predictions)\n",
    "lr_precision = precision_evaluator.evaluate(lr_predictions)\n",
    "lr_recall = recall_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(f\"AUC: {lr_auc}\")\n",
    "print(f\"Accuracy: {lr_accuracy}\")\n",
    "print(f\"F1 Score: {lr_f1}\")\n",
    "print(f\"Precision: {lr_precision}\")\n",
    "print(f\"Recall: {lr_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3fa333-27ac-4546-a52b-4acc4e0f0b31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "596c31ee-ba08-4ad1-a886-b7172c70bb7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b84a19e4-7c07-4831-b708-8b44ef6c929c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree model\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"TARGET\")\n",
    "\n",
    "# Train the model\n",
    "dt_model = dt.fit(final_df)\n",
    "\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.transform(final_df)\n",
    "\n",
    "# Show predictions\n",
    "dt_predictions.select(\"features\", \"TARGET\", \"prediction\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05aac0af-c080-4e0c-8d02-44424b3fd45c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c26a202b-6763-4e45-8cfe-98d747a5eb44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Decision Tree Metrics:\")\n",
    "dt_auc = binary_evaluator.evaluate(dt_predictions)\n",
    "dt_accuracy = multiclass_evaluator.evaluate(dt_predictions)\n",
    "dt_f1 = f1_evaluator.evaluate(dt_predictions)\n",
    "dt_precision = precision_evaluator.evaluate(dt_predictions)\n",
    "dt_recall = recall_evaluator.evaluate(dt_predictions)\n",
    "\n",
    "print(f\"AUC: {dt_auc}\")\n",
    "print(f\"Accuracy: {dt_accuracy}\")\n",
    "print(f\"F1 Score: {dt_f1}\")\n",
    "print(f\"Precision: {dt_precision}\")\n",
    "print(f\"Recall: {dt_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d6b045d-02e9-4507-a0b8-ba0794a3bff2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baccfd6f-c77f-4e48-a2d5-53177a48b6cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6d910b0-8028-4c25-8ba5-f191221263a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eedbda24-8fb4-45ac-9e4c-af721c82cff1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip show xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec01f3db-8c5f-4ae1-988d-7a6281f24ab0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8673bd-6cc7-4389-af6a-caaea9de7e99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# แปลง Spark DataFrame เป็น Pandas DataFrame เพื่อใช้กับ XGBoost\n",
    "final_pandas_df = final_df.select(\"features\", \"TARGET\").toPandas()\n",
    "\n",
    "# สร้าง DMatrix สำหรับ XGBoost\n",
    "dtrain = xgb.DMatrix(data=final_pandas_df['features'].tolist(), label=final_pandas_df['TARGET'])\n",
    "\n",
    "# สร้างโมเดล XGBoost\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"scale_pos_weight\": 10,  # ใช้จัดการข้อมูลไม่สมดุล\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.1,\n",
    "    \"num_round\": 100\n",
    "}\n",
    "\n",
    "# ฝึกโมเดล XGBoost\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# ทำนายผล\n",
    "predictions = xgb_model.predict(dtrain)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5218239e-1961-4779-b8fd-330919fa80e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### ผลลัพธ์ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "004ee1ff-89f7-4931-a6c8-11ec86115446",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "# ทำนายผล (หลังจากที่ฝึกโมเดลเสร็จ)\n",
    "predictions_prob = xgb_model.predict(dtrain)  # ผลลัพธ์เป็นความน่าจะเป็น\n",
    "\n",
    "# แปลงค่าความน่าจะเป็นเป็น class (0 หรือ 1)\n",
    "threshold = 0.5\n",
    "predictions_class = [1 if prob > threshold else 0 for prob in predictions_prob]\n",
    "\n",
    "# ค่าเป้าหมาย (label) ที่แท้จริงจาก dtrain\n",
    "y_true = final_pandas_df['TARGET']\n",
    "\n",
    "# 1. คำนวณ AUC-ROC\n",
    "auc = roc_auc_score(y_true, predictions_prob)\n",
    "print(f\"AUC-ROC: {auc}\")\n",
    "\n",
    "# 2. คำนวณ Accuracy\n",
    "accuracy = accuracy_score(y_true, predictions_class)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# 3. คำนวณ F1-Score\n",
    "f1 = f1_score(y_true, predictions_class)\n",
    "print(f\"F1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45b0defb-0f96-42dd-ba34-299f4e2223d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Add scale_pos_weight For imbalance Data ,num_boost_round up to 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "305b90be-5cbc-4209-a418-9907bf2063ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "add Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec22648a-842e-416f-9dbd-87ada49377c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "# คำนวณ scale_pos_weight จากข้อมูลที่ไม่สมดุล\n",
    "num_negatives = len(final_pandas_df[final_pandas_df['TARGET'] == 0])\n",
    "num_positives = len(final_pandas_df[final_pandas_df['TARGET'] == 1])\n",
    "scale_pos_weight = num_negatives / num_positives\n",
    "\n",
    "# สร้าง DMatrix สำหรับ XGBoost\n",
    "dtrain = xgb.DMatrix(data=final_pandas_df['features'].tolist(), label=final_pandas_df['TARGET'])\n",
    "\n",
    "# ปรับพารามิเตอร์ของ XGBoost สำหรับข้อมูลไม่สมดุลและข้อมูลขนาดใหญ่\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"scale_pos_weight\": scale_pos_weight,  # ใช้เพื่อจัดการกับข้อมูลไม่สมดุล\n",
    "    \"max_depth\": 7,            # ความลึกของต้นไม้\n",
    "    \"eta\": 0.3,                # อัตราการเรียนรู้\n",
    "    \"n_estimators\": 500,       # จำนวนต้นไม้\n",
    "    \"subsample\": 0.8,          # สัดส่วนของข้อมูลที่ใช้สร้างต้นไม้\n",
    "    \"colsample_bytree\": 0.8    # สัดส่วนของฟีเจอร์ที่สุ่มเลือกในการสร้างต้นไม้\n",
    "}\n",
    "\n",
    "# ฝึกโมเดล\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=1500)\n",
    "\n",
    "# ทำนายผล\n",
    "predictions_prob = xgb_model.predict(dtrain)\n",
    "\n",
    "# แปลงค่าความน่าจะเป็นเป็น class\n",
    "threshold = 0.5\n",
    "predictions_class = [1 if prob > threshold else 0 for prob in predictions_prob]\n",
    "\n",
    "# ค่าเป้าหมายที่แท้จริง\n",
    "y_true = final_pandas_df['TARGET']\n",
    "\n",
    "# คำนวณ AUC-ROC, Accuracy, และ F1-Score\n",
    "auc = roc_auc_score(y_true, predictions_prob)\n",
    "accuracy = accuracy_score(y_true, predictions_class)\n",
    "f1 = f1_score(y_true, predictions_class)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(f\"AUC-ROC: {auc}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc4110cc-f057-4bed-bfdb-f9d9ecc7036c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b2fd97-0a2a-49de-baa1-54b6724e336a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# บันทึกโมเดล XGBoost ลงในโฟลเดอร์ชั่วคราว (/tmp/)\n",
    "with open('/tmp/my_xgboost_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(xgb_model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e2ecf74-d35e-4ef0-9e93-2451a933a6e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5901d34d-54a1-4d5a-a0c2-eab428bfcbf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\"file:/tmp/my_xgboost_model.pkl\", \"dbfs:/FileStore/my_xgboost_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "194a8d4d-da51-4e98-8d54-53e4d88162e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /FileStore/\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2836101004968792,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "BigDataProject_Loan Default",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
